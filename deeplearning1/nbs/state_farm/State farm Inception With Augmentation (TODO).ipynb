{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Farm (no data augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:\n",
    "\n",
    "1. load train and validation data\n",
    "2. load VGG model\n",
    "3. remove final layer and precompute\n",
    "4. replace final layer\n",
    "5. train\n",
    "6. test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "floydhub = False\n",
    "sample = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./bottlenecks/’: File exists\n",
      "mkdir: cannot create directory ‘./results/’: File exists\n"
     ]
    }
   ],
   "source": [
    "if floydhub:\n",
    "    data_path = \"/input/\"\n",
    "    bottleneck_path = \"/output/bottlenecks/\"\n",
    "    results_path = \"/output/results/\"\n",
    "else:\n",
    "    data_path = \"./data/\"\n",
    "    if sample:\n",
    "        data_path += \"sample/\"\n",
    "    bottleneck_path = \"./bottlenecks/\"\n",
    "    results_path = \"./results/\"\n",
    "%mkdir $bottleneck_path\n",
    "%mkdir $results_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19658 images belonging to 10 classes.\n",
      "Found 2766 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "from utils import get_data, get_classes\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "gen = ImageDataGenerator(featurewise_center=False, samplewise_center=False)\n",
    "\n",
    "train_data = get_data(data_path + \"train\")\n",
    "valid_data = get_data(data_path + \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19658 images belonging to 10 classes.\n",
      "Found 2766 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "val_classes, train_classes, val_labels, train_labels, _,_,_ = get_classes(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_6 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 299, 299)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_7 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 299, 299)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers.core import Flatten, Lambda, Dense, Dropout\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "input = Input(shape=(3, 299, 299))\n",
    "base_model = InceptionV3(weights=\"imagenet\", include_top=False)\n",
    "\n",
    "preprocessor = Lambda(preprocess_input)\n",
    "output = base_model(preprocessor(input))\n",
    "#output = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=input, output=x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/layers/core.py:622: UserWarning: `output_shape` argument not specified for layer lambda_9 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 3, 299, 299)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.layers.core import Flatten, Lambda, Dense, Dropout\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "input = Input(shape=(3, 299, 299))\n",
    "preprocessor = Lambda(preprocess_input)\n",
    "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_tensor=preprocessor(input))\n",
    "for l in base_model.layers: l.trainable=False\n",
    "output = base_model.output\n",
    "\n",
    "x = GlobalAveragePooling2D()(output)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input=input, output=x)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_14 (InputLayer)            (None, 3, 299, 299)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, 3, 299, 299)   0           input_14[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_659 (Convolution2D (None, 32, 149, 149)  896         lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_664 (BatchNor (None, 32, 149, 149)  128         convolution2d_659[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_660 (Convolution2D (None, 32, 147, 147)  9248        batchnormalization_664[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_665 (BatchNor (None, 32, 147, 147)  128         convolution2d_660[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_661 (Convolution2D (None, 64, 147, 147)  18496       batchnormalization_665[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_666 (BatchNor (None, 64, 147, 147)  256         convolution2d_661[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_22 (MaxPooling2D)   (None, 64, 73, 73)    0           batchnormalization_666[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_662 (Convolution2D (None, 80, 73, 73)    5200        maxpooling2d_22[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_667 (BatchNor (None, 80, 73, 73)    320         convolution2d_662[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_663 (Convolution2D (None, 192, 71, 71)   138432      batchnormalization_667[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_668 (BatchNor (None, 192, 71, 71)   768         convolution2d_663[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_23 (MaxPooling2D)   (None, 192, 35, 35)   0           batchnormalization_668[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_667 (Convolution2D (None, 64, 35, 35)    12352       maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_672 (BatchNor (None, 64, 35, 35)    256         convolution2d_667[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_665 (Convolution2D (None, 48, 35, 35)    9264        maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_668 (Convolution2D (None, 96, 35, 35)    55392       batchnormalization_672[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_670 (BatchNor (None, 48, 35, 35)    192         convolution2d_665[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_673 (BatchNor (None, 96, 35, 35)    384         convolution2d_668[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_71 (AveragePool (None, 192, 35, 35)   0           maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_664 (Convolution2D (None, 64, 35, 35)    12352       maxpooling2d_23[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_666 (Convolution2D (None, 64, 35, 35)    76864       batchnormalization_670[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_669 (Convolution2D (None, 96, 35, 35)    83040       batchnormalization_673[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_670 (Convolution2D (None, 32, 35, 35)    6176        averagepooling2d_71[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_669 (BatchNor (None, 64, 35, 35)    256         convolution2d_664[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_671 (BatchNor (None, 64, 35, 35)    256         convolution2d_666[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_674 (BatchNor (None, 96, 35, 35)    384         convolution2d_669[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_675 (BatchNor (None, 32, 35, 35)    128         convolution2d_670[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed0 (Merge)                   (None, 256, 35, 35)   0           batchnormalization_669[0][0]     \n",
      "                                                                   batchnormalization_671[0][0]     \n",
      "                                                                   batchnormalization_674[0][0]     \n",
      "                                                                   batchnormalization_675[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_674 (Convolution2D (None, 64, 35, 35)    16448       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_679 (BatchNor (None, 64, 35, 35)    256         convolution2d_674[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_672 (Convolution2D (None, 48, 35, 35)    12336       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_675 (Convolution2D (None, 96, 35, 35)    55392       batchnormalization_679[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_677 (BatchNor (None, 48, 35, 35)    192         convolution2d_672[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_680 (BatchNor (None, 96, 35, 35)    384         convolution2d_675[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_72 (AveragePool (None, 256, 35, 35)   0           mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_671 (Convolution2D (None, 64, 35, 35)    16448       mixed0[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_673 (Convolution2D (None, 64, 35, 35)    76864       batchnormalization_677[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_676 (Convolution2D (None, 96, 35, 35)    83040       batchnormalization_680[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_677 (Convolution2D (None, 32, 35, 35)    8224        averagepooling2d_72[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_676 (BatchNor (None, 64, 35, 35)    256         convolution2d_671[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_678 (BatchNor (None, 64, 35, 35)    256         convolution2d_673[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_681 (BatchNor (None, 96, 35, 35)    384         convolution2d_676[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_682 (BatchNor (None, 32, 35, 35)    128         convolution2d_677[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed1 (Merge)                   (None, 256, 35, 35)   0           batchnormalization_676[0][0]     \n",
      "                                                                   batchnormalization_678[0][0]     \n",
      "                                                                   batchnormalization_681[0][0]     \n",
      "                                                                   batchnormalization_682[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_681 (Convolution2D (None, 64, 35, 35)    16448       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_686 (BatchNor (None, 64, 35, 35)    256         convolution2d_681[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_679 (Convolution2D (None, 48, 35, 35)    12336       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_682 (Convolution2D (None, 96, 35, 35)    55392       batchnormalization_686[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_684 (BatchNor (None, 48, 35, 35)    192         convolution2d_679[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_687 (BatchNor (None, 96, 35, 35)    384         convolution2d_682[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_73 (AveragePool (None, 256, 35, 35)   0           mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_678 (Convolution2D (None, 64, 35, 35)    16448       mixed1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_680 (Convolution2D (None, 64, 35, 35)    76864       batchnormalization_684[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_683 (Convolution2D (None, 96, 35, 35)    83040       batchnormalization_687[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_684 (Convolution2D (None, 32, 35, 35)    8224        averagepooling2d_73[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_683 (BatchNor (None, 64, 35, 35)    256         convolution2d_678[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_685 (BatchNor (None, 64, 35, 35)    256         convolution2d_680[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_688 (BatchNor (None, 96, 35, 35)    384         convolution2d_683[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_689 (BatchNor (None, 32, 35, 35)    128         convolution2d_684[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed2 (Merge)                   (None, 256, 35, 35)   0           batchnormalization_683[0][0]     \n",
      "                                                                   batchnormalization_685[0][0]     \n",
      "                                                                   batchnormalization_688[0][0]     \n",
      "                                                                   batchnormalization_689[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_686 (Convolution2D (None, 64, 35, 35)    16448       mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_691 (BatchNor (None, 64, 35, 35)    256         convolution2d_686[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_687 (Convolution2D (None, 96, 35, 35)    55392       batchnormalization_691[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_692 (BatchNor (None, 96, 35, 35)    384         convolution2d_687[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_685 (Convolution2D (None, 384, 17, 17)   885120      mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_688 (Convolution2D (None, 96, 17, 17)    83040       batchnormalization_692[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_690 (BatchNor (None, 384, 17, 17)   1536        convolution2d_685[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_693 (BatchNor (None, 96, 17, 17)    384         convolution2d_688[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_24 (MaxPooling2D)   (None, 256, 17, 17)   0           mixed2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed3 (Merge)                   (None, 736, 17, 17)   0           batchnormalization_690[0][0]     \n",
      "                                                                   batchnormalization_693[0][0]     \n",
      "                                                                   maxpooling2d_24[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_693 (Convolution2D (None, 128, 17, 17)   94336       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_698 (BatchNor (None, 128, 17, 17)   512         convolution2d_693[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_694 (Convolution2D (None, 128, 17, 17)   114816      batchnormalization_698[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_699 (BatchNor (None, 128, 17, 17)   512         convolution2d_694[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_690 (Convolution2D (None, 128, 17, 17)   94336       mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_695 (Convolution2D (None, 128, 17, 17)   114816      batchnormalization_699[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_695 (BatchNor (None, 128, 17, 17)   512         convolution2d_690[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_700 (BatchNor (None, 128, 17, 17)   512         convolution2d_695[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_691 (Convolution2D (None, 128, 17, 17)   114816      batchnormalization_695[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_696 (Convolution2D (None, 128, 17, 17)   114816      batchnormalization_700[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_696 (BatchNor (None, 128, 17, 17)   512         convolution2d_691[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_701 (BatchNor (None, 128, 17, 17)   512         convolution2d_696[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_74 (AveragePool (None, 736, 17, 17)   0           mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_689 (Convolution2D (None, 192, 17, 17)   141504      mixed3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_692 (Convolution2D (None, 192, 17, 17)   172224      batchnormalization_696[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_697 (Convolution2D (None, 192, 17, 17)   172224      batchnormalization_701[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_698 (Convolution2D (None, 192, 17, 17)   141504      averagepooling2d_74[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_694 (BatchNor (None, 192, 17, 17)   768         convolution2d_689[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_697 (BatchNor (None, 192, 17, 17)   768         convolution2d_692[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_702 (BatchNor (None, 192, 17, 17)   768         convolution2d_697[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_703 (BatchNor (None, 192, 17, 17)   768         convolution2d_698[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed4 (Merge)                   (None, 768, 17, 17)   0           batchnormalization_694[0][0]     \n",
      "                                                                   batchnormalization_697[0][0]     \n",
      "                                                                   batchnormalization_702[0][0]     \n",
      "                                                                   batchnormalization_703[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_703 (Convolution2D (None, 160, 17, 17)   123040      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_708 (BatchNor (None, 160, 17, 17)   640         convolution2d_703[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_704 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_708[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_709 (BatchNor (None, 160, 17, 17)   640         convolution2d_704[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_700 (Convolution2D (None, 160, 17, 17)   123040      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_705 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_709[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_705 (BatchNor (None, 160, 17, 17)   640         convolution2d_700[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_710 (BatchNor (None, 160, 17, 17)   640         convolution2d_705[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_701 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_705[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_706 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_710[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_706 (BatchNor (None, 160, 17, 17)   640         convolution2d_701[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_711 (BatchNor (None, 160, 17, 17)   640         convolution2d_706[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_75 (AveragePool (None, 768, 17, 17)   0           mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_699 (Convolution2D (None, 192, 17, 17)   147648      mixed4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_702 (Convolution2D (None, 192, 17, 17)   215232      batchnormalization_706[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_707 (Convolution2D (None, 192, 17, 17)   215232      batchnormalization_711[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_708 (Convolution2D (None, 192, 17, 17)   147648      averagepooling2d_75[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_704 (BatchNor (None, 192, 17, 17)   768         convolution2d_699[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_707 (BatchNor (None, 192, 17, 17)   768         convolution2d_702[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_712 (BatchNor (None, 192, 17, 17)   768         convolution2d_707[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_713 (BatchNor (None, 192, 17, 17)   768         convolution2d_708[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed5 (Merge)                   (None, 768, 17, 17)   0           batchnormalization_704[0][0]     \n",
      "                                                                   batchnormalization_707[0][0]     \n",
      "                                                                   batchnormalization_712[0][0]     \n",
      "                                                                   batchnormalization_713[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_713 (Convolution2D (None, 160, 17, 17)   123040      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_718 (BatchNor (None, 160, 17, 17)   640         convolution2d_713[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_714 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_718[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_719 (BatchNor (None, 160, 17, 17)   640         convolution2d_714[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_710 (Convolution2D (None, 160, 17, 17)   123040      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_715 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_719[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_715 (BatchNor (None, 160, 17, 17)   640         convolution2d_710[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_720 (BatchNor (None, 160, 17, 17)   640         convolution2d_715[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_711 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_715[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_716 (Convolution2D (None, 160, 17, 17)   179360      batchnormalization_720[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_716 (BatchNor (None, 160, 17, 17)   640         convolution2d_711[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_721 (BatchNor (None, 160, 17, 17)   640         convolution2d_716[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_76 (AveragePool (None, 768, 17, 17)   0           mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_709 (Convolution2D (None, 192, 17, 17)   147648      mixed5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_712 (Convolution2D (None, 192, 17, 17)   215232      batchnormalization_716[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_717 (Convolution2D (None, 192, 17, 17)   215232      batchnormalization_721[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_718 (Convolution2D (None, 192, 17, 17)   147648      averagepooling2d_76[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_714 (BatchNor (None, 192, 17, 17)   768         convolution2d_709[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_717 (BatchNor (None, 192, 17, 17)   768         convolution2d_712[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_722 (BatchNor (None, 192, 17, 17)   768         convolution2d_717[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_723 (BatchNor (None, 192, 17, 17)   768         convolution2d_718[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed6 (Merge)                   (None, 768, 17, 17)   0           batchnormalization_714[0][0]     \n",
      "                                                                   batchnormalization_717[0][0]     \n",
      "                                                                   batchnormalization_722[0][0]     \n",
      "                                                                   batchnormalization_723[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_723 (Convolution2D (None, 160, 17, 17)   123040      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_728 (BatchNor (None, 160, 17, 17)   640         convolution2d_723[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_724 (Convolution2D (None, 192, 17, 17)   215232      batchnormalization_728[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_729 (BatchNor (None, 192, 17, 17)   768         convolution2d_724[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_720 (Convolution2D (None, 192, 17, 17)   147648      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_725 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_729[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_725 (BatchNor (None, 192, 17, 17)   768         convolution2d_720[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_730 (BatchNor (None, 192, 17, 17)   768         convolution2d_725[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_721 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_725[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_726 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_730[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_726 (BatchNor (None, 192, 17, 17)   768         convolution2d_721[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_731 (BatchNor (None, 192, 17, 17)   768         convolution2d_726[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_77 (AveragePool (None, 768, 17, 17)   0           mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_719 (Convolution2D (None, 192, 17, 17)   147648      mixed6[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_722 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_726[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_727 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_731[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_728 (Convolution2D (None, 192, 17, 17)   147648      averagepooling2d_77[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_724 (BatchNor (None, 192, 17, 17)   768         convolution2d_719[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_727 (BatchNor (None, 192, 17, 17)   768         convolution2d_722[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_732 (BatchNor (None, 192, 17, 17)   768         convolution2d_727[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_733 (BatchNor (None, 192, 17, 17)   768         convolution2d_728[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed7 (Merge)                   (None, 768, 17, 17)   0           batchnormalization_724[0][0]     \n",
      "                                                                   batchnormalization_727[0][0]     \n",
      "                                                                   batchnormalization_732[0][0]     \n",
      "                                                                   batchnormalization_733[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_731 (Convolution2D (None, 192, 17, 17)   147648      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_736 (BatchNor (None, 192, 17, 17)   768         convolution2d_731[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_732 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_736[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_737 (BatchNor (None, 192, 17, 17)   768         convolution2d_732[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_729 (Convolution2D (None, 192, 17, 17)   147648      mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_733 (Convolution2D (None, 192, 17, 17)   258240      batchnormalization_737[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_734 (BatchNor (None, 192, 17, 17)   768         convolution2d_729[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_738 (BatchNor (None, 192, 17, 17)   768         convolution2d_733[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_730 (Convolution2D (None, 320, 8, 8)     553280      batchnormalization_734[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_734 (Convolution2D (None, 192, 8, 8)     331968      batchnormalization_738[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_735 (BatchNor (None, 320, 8, 8)     1280        convolution2d_730[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_739 (BatchNor (None, 192, 8, 8)     768         convolution2d_734[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_78 (AveragePool (None, 768, 8, 8)     0           mixed7[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "mixed8 (Merge)                   (None, 1280, 8, 8)    0           batchnormalization_735[0][0]     \n",
      "                                                                   batchnormalization_739[0][0]     \n",
      "                                                                   averagepooling2d_78[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_739 (Convolution2D (None, 448, 8, 8)     573888      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_744 (BatchNor (None, 448, 8, 8)     1792        convolution2d_739[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_736 (Convolution2D (None, 384, 8, 8)     491904      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_740 (Convolution2D (None, 384, 8, 8)     1548672     batchnormalization_744[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_741 (BatchNor (None, 384, 8, 8)     1536        convolution2d_736[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_745 (BatchNor (None, 384, 8, 8)     1536        convolution2d_740[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_737 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_741[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_738 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_741[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_741 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_745[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_742 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_745[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_79 (AveragePool (None, 1280, 8, 8)    0           mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_735 (Convolution2D (None, 320, 8, 8)     409920      mixed8[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_742 (BatchNor (None, 384, 8, 8)     1536        convolution2d_737[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_743 (BatchNor (None, 384, 8, 8)     1536        convolution2d_738[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_746 (BatchNor (None, 384, 8, 8)     1536        convolution2d_741[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_747 (BatchNor (None, 384, 8, 8)     1536        convolution2d_742[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_743 (Convolution2D (None, 192, 8, 8)     245952      averagepooling2d_79[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_740 (BatchNor (None, 320, 8, 8)     1280        convolution2d_735[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_0 (Merge)                 (None, 768, 8, 8)     0           batchnormalization_742[0][0]     \n",
      "                                                                   batchnormalization_743[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "merge_15 (Merge)                 (None, 768, 8, 8)     0           batchnormalization_746[0][0]     \n",
      "                                                                   batchnormalization_747[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_748 (BatchNor (None, 192, 8, 8)     768         convolution2d_743[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed9 (Merge)                   (None, 2048, 8, 8)    0           batchnormalization_740[0][0]     \n",
      "                                                                   mixed9_0[0][0]                   \n",
      "                                                                   merge_15[0][0]                   \n",
      "                                                                   batchnormalization_748[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_748 (Convolution2D (None, 448, 8, 8)     917952      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_753 (BatchNor (None, 448, 8, 8)     1792        convolution2d_748[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_745 (Convolution2D (None, 384, 8, 8)     786816      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_749 (Convolution2D (None, 384, 8, 8)     1548672     batchnormalization_753[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_750 (BatchNor (None, 384, 8, 8)     1536        convolution2d_745[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_754 (BatchNor (None, 384, 8, 8)     1536        convolution2d_749[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_746 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_750[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_747 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_750[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_750 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_754[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_751 (Convolution2D (None, 384, 8, 8)     442752      batchnormalization_754[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "averagepooling2d_80 (AveragePool (None, 2048, 8, 8)    0           mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_744 (Convolution2D (None, 320, 8, 8)     655680      mixed9[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_751 (BatchNor (None, 384, 8, 8)     1536        convolution2d_746[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_752 (BatchNor (None, 384, 8, 8)     1536        convolution2d_747[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_755 (BatchNor (None, 384, 8, 8)     1536        convolution2d_750[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_756 (BatchNor (None, 384, 8, 8)     1536        convolution2d_751[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_752 (Convolution2D (None, 192, 8, 8)     393408      averagepooling2d_80[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_749 (BatchNor (None, 320, 8, 8)     1280        convolution2d_744[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed9_1 (Merge)                 (None, 768, 8, 8)     0           batchnormalization_751[0][0]     \n",
      "                                                                   batchnormalization_752[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "merge_16 (Merge)                 (None, 768, 8, 8)     0           batchnormalization_755[0][0]     \n",
      "                                                                   batchnormalization_756[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_757 (BatchNor (None, 192, 8, 8)     768         convolution2d_752[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mixed10 (Merge)                  (None, 2048, 8, 8)    0           batchnormalization_749[0][0]     \n",
      "                                                                   mixed9_1[0][0]                   \n",
      "                                                                   merge_16[0][0]                   \n",
      "                                                                   batchnormalization_757[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "globalaveragepooling2d_6 (Global (None, 2048)          0           mixed10[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 1024)          2098176     globalaveragepooling2d_6[0][0]   \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_758 (BatchNor (None, 1024)          4096        dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 1024)          0           batchnormalization_758[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 10)            10250       dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 23,724,490\n",
      "Trainable params: 2,110,474\n",
      "Non-trainable params: 21,614,016\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5696/19658 [=======>......................] - ETA: 343s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "train_bottlenecks = model.predict(train_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valid_bottlenecks = vgg.model.predict(valid_data, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import save_array\n",
    "save_array(bottleneck_path+\"train_bottlenecks_new.bc\", train_bottlenecks)\n",
    "save_array(bottleneck_path+\"valid_bottlenecks_new.bc\", valid_bottlenecks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "for layer in vgg.model.layers:\n",
    "    layer.trainable = False\n",
    "fc_model = Sequential([\n",
    "    BatchNormalization(input_shape=train_bottlenecks.shape[1:]),\n",
    "    Dense(4096, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    Dense(4096, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.7),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "fc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19658 samples, validate on 2766 samples\n",
      "Epoch 1/10\n",
      "34s - loss: 2.5659 - acc: 0.7786 - val_loss: 3.2536 - val_acc: 0.7661\n",
      "Epoch 2/10\n",
      "34s - loss: 0.6800 - acc: 0.9464 - val_loss: 3.3381 - val_acc: 0.7722\n",
      "Epoch 3/10\n",
      "34s - loss: 0.4817 - acc: 0.9633 - val_loss: 4.5080 - val_acc: 0.6920\n",
      "Epoch 4/10\n",
      "34s - loss: 0.3854 - acc: 0.9710 - val_loss: 3.9118 - val_acc: 0.7379\n",
      "Epoch 5/10\n",
      "34s - loss: 0.3739 - acc: 0.9733 - val_loss: 3.6164 - val_acc: 0.7570\n",
      "Epoch 6/10\n",
      "34s - loss: 0.3139 - acc: 0.9775 - val_loss: 5.0132 - val_acc: 0.6757\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-01373d9c2715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_bottlenecks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_bottlenecks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fc_model.optimizer.lr = 0.01\n",
    "fc_model.fit(train_bottlenecks, train_labels, nb_epoch=10, validation_data=(valid_bottlenecks, val_labels), batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19658 samples, validate on 2766 samples\n",
      "Epoch 1/10\n",
      "34s - loss: 1.2223 - acc: 0.9040 - val_loss: 2.6419 - val_acc: 0.8106\n",
      "Epoch 2/10\n",
      "34s - loss: 0.1679 - acc: 0.9854 - val_loss: 2.8714 - val_acc: 0.7874\n",
      "Epoch 3/10\n",
      "34s - loss: 0.1506 - acc: 0.9871 - val_loss: 2.8443 - val_acc: 0.8040\n",
      "Epoch 4/10\n",
      "34s - loss: 0.1111 - acc: 0.9906 - val_loss: 3.1820 - val_acc: 0.7824\n",
      "Epoch 5/10\n",
      "34s - loss: 0.1055 - acc: 0.9910 - val_loss: 5.1031 - val_acc: 0.6565\n",
      "Epoch 6/10\n",
      "34s - loss: 0.0990 - acc: 0.9915 - val_loss: 4.2108 - val_acc: 0.7119\n",
      "Epoch 7/10\n",
      "34s - loss: 0.1185 - acc: 0.9910 - val_loss: 3.5692 - val_acc: 0.7585\n",
      "Epoch 8/10\n",
      "34s - loss: 0.1364 - acc: 0.9893 - val_loss: 3.2212 - val_acc: 0.7842\n",
      "Epoch 9/10\n",
      "34s - loss: 0.1978 - acc: 0.9856 - val_loss: 8.5893 - val_acc: 0.4487\n",
      "Epoch 10/10\n",
      "34s - loss: 0.2587 - acc: 0.9812 - val_loss: 4.5169 - val_acc: 0.7057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbfbb6b8d10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.optimizer.lr = 0.001\n",
    "fc_model.fit(train_bottlenecks, train_labels, nb_epoch=10, validation_data=(valid_bottlenecks, val_labels), batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19658 samples, validate on 2766 samples\n",
      "Epoch 1/10\n",
      "34s - loss: 0.3102 - acc: 0.9784 - val_loss: 3.3973 - val_acc: 0.7795\n",
      "Epoch 2/10\n",
      "34s - loss: 0.2523 - acc: 0.9824 - val_loss: 4.9321 - val_acc: 0.6790\n",
      "Epoch 3/10\n",
      "35s - loss: 0.2751 - acc: 0.9809 - val_loss: 4.1010 - val_acc: 0.7328\n",
      "Epoch 4/10\n",
      "36s - loss: 0.2579 - acc: 0.9828 - val_loss: 3.7483 - val_acc: 0.7603\n",
      "Epoch 5/10\n",
      "36s - loss: 0.2853 - acc: 0.9807 - val_loss: 3.9531 - val_acc: 0.7415\n",
      "Epoch 6/10\n",
      "36s - loss: 0.2861 - acc: 0.9807 - val_loss: 3.8220 - val_acc: 0.7552\n",
      "Epoch 7/10\n",
      "36s - loss: 0.2807 - acc: 0.9814 - val_loss: 3.7130 - val_acc: 0.7636\n",
      "Epoch 8/10\n",
      "36s - loss: 0.2566 - acc: 0.9829 - val_loss: 3.4171 - val_acc: 0.7849\n",
      "Epoch 9/10\n",
      "37s - loss: 0.2560 - acc: 0.9832 - val_loss: 3.3395 - val_acc: 0.7881\n",
      "Epoch 10/10\n",
      "37s - loss: 0.3250 - acc: 0.9787 - val_loss: 3.3976 - val_acc: 0.7838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbfbb6b8a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.optimizer.lr = 0.0001\n",
    "fc_model.fit(train_bottlenecks, train_labels, nb_epoch=10, validation_data=(valid_bottlenecks, val_labels), batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bottlenecks  results\t\t\t\t     utils.pyc\t  vgg16.pyc\r\n",
      "data\t     State farm VGG 0.ipynb\t\t     vgg16bn.py\r\n",
      "download.sh  State farm VGG Data augmentation.ipynb  vgg16bn.pyc\r\n",
      "mkdata.py    utils.py\t\t\t\t     vgg16.py\r\n"
     ]
    }
   ],
   "source": [
    "!sudo ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
